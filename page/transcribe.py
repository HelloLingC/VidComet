import streamlit as st
from core import log_utils, whisper_local, demucs_local
from core.config_utils import *
import os
import builtins

old_print = builtins.print

def hook_print():
    def hook(*args, **kwargs):
        old_print("lol", end='')
        old_print(*args, **kwargs)
        update(" ".join(args))
    builtins.print = hook

def unhook_print():
    builtins.print = old_print

st_progress = None
progress = 0
def update(msg):
    global progress
    progress += 1
    # st_progress.progress(progress / 30, "Processing...")
    st_progress.status(msg)

def check_whisper_models():
    pass

st_asr_result = None
def start_asr():
    demucs_local.start_demucs()
    st_asr_result.success('äººå£°åˆ†ç¦»æˆåŠŸï¼')
    st_asr_result.markdown(f'ç»“æœä¿å­˜åœ¨ `{VOCAL_AUDIO_FILE_PATH}`')
    st_asr_result.audio((VOCAL_AUDIO_FILE_PATH))

st_trans_result = None
def start_transcribe():
    vid_file = st.session_state.vid_file
    # process = subprocess.Popen(['python', 'core/whisper_local.py', vid_file], stdout=subprocess.PIPE)
    # hook_print()
    whisper_local.transcribe(vid_file)
    # unhook_print()
    # while True:
    #     output = process.stdout.readline()
    #     if output == '' and process.poll() is not None:
    #         break
    #     if output:
    #         print(output.strip())
    if os.path.exists(VOCAL_AUDIO_FILE_PATH):
        st.session_state.step = 3
        st_trans_result.success('éŸ³é¢‘è½¬å½•æˆåŠŸï¼')
        st_trans_result.markdown(f'ç»“æœä¿å­˜åœ¨ `{TRANSCRIPTION_SENT_PATH}`')
        st_trans_result.write(open(TRANSCRIPTION_SENT_PATH, 'r', encoding='utf-8'))
    else:
        st_trans_result.error('VOCAL FILE NOT EXISTED')

def main():
    global st_trans_result
    global st_asr_result
    global st_progress

    st.header('ğŸ§è¯­éŸ³è¯†åˆ«')
    tab = st.tabs(['ä¸»é¡µ', 'é…ç½®'])
    with tab[0]:
        pass

    st.session_state.vid_existed = 'vid_file' in st.session_state
    if st.session_state.vid_existed:
        vid_file = st.session_state.vid_file
        origin_path = st.text_input('è§†é¢‘æ–‡ä»¶', vid_file)
    else:
        origin_path = st.text_input('è§†é¢‘æ–‡ä»¶', '')

    if origin_path == '':
        st.error('è§†é¢‘æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©ºï¼')

    with st.container(border=True):
        st.subheader('äººå£°åˆ†ç¦»')
        st.selectbox('æ¨¡å‹', ['htdemucs', 'htdemucs-ft', 'htdemucs_6s', 'mdx_extra_q'])
        st_progress = st.empty()
        st.button("å¼€å§‹", icon='ğŸš€', on_click=start_asr, disabled=(origin_path == ''))
        st_asr_result = st.container()

    with st.container(border=True):
        st.subheader('è¯­éŸ³è¯†åˆ«')
        cols = st.columns(2)
        cols[0].selectbox('é€‰æ‹©æ¨¡å‹', ['large-v3-turbo', 'large-v2', 'large-v3'])
        cols[1].selectbox('ç›®æ ‡è¯­è¨€', ['è‡ªåŠ¨æ£€æµ‹', 'English', 'ä¸­æ–‡'])
        st_progress = st.empty()
        st.button("å¼€å§‹è½¬å½•", icon='ğŸš€', on_click=start_transcribe, disabled=(origin_path == ''))
        st_trans_result = st.container()


    log_utils.observable_handler.subscribe(update)
    # if not 'step' in st.session_state:
    #     st.button('å¼€å§‹', icon='ğŸš€', on_click=start_transcribe)
    # else:
    #     if(st.button('ä¸‹ä¸€æ­¥', icon='ğŸš€')):
    #         st.switch_page('page/splitter.py')
    #     st.write('è¯­éŸ³è¯†åˆ«: ', open(TRANSCRIPTION_SENT_PATH, 'r').readlines())


main()

